{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsRegressor  # 补充K近邻回归\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#Reading all the file\n",
    "yello_taxi_2023_01 = pd.read_parquet(\"Data/2023_01.parquet\")\n",
    "yello_taxi_2023_02 = pd.read_parquet(\"Data/2023_02.parquet\")\n",
    "yello_taxi_2023_03 = pd.read_parquet(\"Data/2023_03.parquet\")\n",
    "yello_taxi_2023_04 = pd.read_parquet(\"Data/2023_04.parquet\")\n",
    "yello_taxi_2023_05 = pd.read_parquet(\"Data/2023_05.parquet\")\n",
    "yello_taxi_2023_06 = pd.read_parquet(\"Data/2023_06.parquet\")\n",
    "yello_taxi_2023_07 = pd.read_parquet(\"Data/2023_07.parquet\")\n",
    "yello_taxi_2023_08 = pd.read_parquet(\"Data/2023_08.parquet\")\n",
    "yello_taxi_2023_09 = pd.read_parquet(\"Data/2023_09.parquet\")\n",
    "yello_taxi_2023_10 = pd.read_parquet(\"Data/2023_10.parquet\")\n",
    "yello_taxi_2023_11 = pd.read_parquet(\"Data/2023_11.parquet\")\n",
    "yello_taxi_2023_12 = pd.read_parquet(\"Data/2023_12.parquet\")\n",
    "\n",
    "yello_taxi_2024_01 = pd.read_parquet(\"Data/2024_01.parquet\")\n",
    "yello_taxi_2024_02 = pd.read_parquet(\"Data/2024_02.parquet\")\n",
    "yello_taxi_2024_03 = pd.read_parquet(\"Data/2024_03.parquet\")\n",
    "yello_taxi_2024_04 = pd.read_parquet(\"Data/2024_04.parquet\")\n",
    "yello_taxi_2024_05 = pd.read_parquet(\"Data/2024_05.parquet\")\n",
    "yello_taxi_2024_06 = pd.read_parquet(\"Data/2024_06.parquet\")\n",
    "yello_taxi_2024_07 = pd.read_parquet(\"Data/2024_07.parquet\")\n",
    "yello_taxi_2024_08 = pd.read_parquet(\"Data/2024_08.parquet\")\n",
    "yello_taxi_2024_09 = pd.read_parquet(\"Data/2024_09.parquet\")\n",
    "yello_taxi_2024_10 = pd.read_parquet(\"Data/2024_10.parquet\")\n",
    "yello_taxi_2024_11 = pd.read_parquet(\"Data/2024_11.parquet\")\n",
    "\n",
    "\n",
    "sum_dataset = pd.concat([yello_taxi_2023_01,yello_taxi_2023_02,yello_taxi_2023_03,\n",
    "            yello_taxi_2023_04,yello_taxi_2023_05,yello_taxi_2023_06,\n",
    "            yello_taxi_2023_07,yello_taxi_2023_08,yello_taxi_2023_09, \n",
    "            yello_taxi_2023_10, yello_taxi_2023_11, yello_taxi_2023_12,\n",
    "            yello_taxi_2024_01, yello_taxi_2024_02, yello_taxi_2024_03,\n",
    "            yello_taxi_2024_04, yello_taxi_2024_05, yello_taxi_2024_06,\n",
    "            yello_taxi_2024_07, yello_taxi_2024_08, yello_taxi_2024_09, \n",
    "            yello_taxi_2024_10, yello_taxi_2024_11\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] 初始数据量: 75811575\n",
      "[2] 基础过滤后: 67854154\n",
      "[3] 时间过滤后: 67851501\n",
      "[4] 速度过滤后: 67781859\n",
      "[5] 最终数据量: 67781856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/kdx178sn0hn6k06q5wb3d6km0000gn/T/ipykernel_9422/2910332292.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"dropoff_hour\"] = final_df[\"tpep_dropoff_datetime\"].dt.hour\n",
      "/var/folders/ms/kdx178sn0hn6k06q5wb3d6km0000gn/T/ipykernel_9422/2910332292.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"dropoff_dayofweek\"] = final_df[\"tpep_dropoff_datetime\"].dt.dayofweek\n",
      "/var/folders/ms/kdx178sn0hn6k06q5wb3d6km0000gn/T/ipykernel_9422/2910332292.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"is_weekend\"] = final_df[\"dropoff_dayofweek\"].isin([5, 6]).astype(int)\n",
      "/var/folders/ms/kdx178sn0hn6k06q5wb3d6km0000gn/T/ipykernel_9422/2910332292.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"time_period\"] = pd.cut(\n"
     ]
    }
   ],
   "source": [
    "def safe_preprocess(df):\n",
    "    # 保留原始数据副本\n",
    "    raw_df = df.copy()\n",
    "    \n",
    "    # 逐步过滤（添加调试输出）\n",
    "    print(\"\\n[1] 初始数据量:\", len(raw_df))\n",
    "    \n",
    "    # 第一轮过滤：基础有效性过滤\n",
    "    cond = (\n",
    "        raw_df[\"passenger_count\"].between(1, 6) &\n",
    "        raw_df[\"trip_distance\"].between(0.1, 100) &\n",
    "        (raw_df[\"total_amount\"] > 0) &\n",
    "        (raw_df[\"tip_amount\"] >= 0) &\n",
    "        raw_df[\"tpep_pickup_datetime\"].notna() &\n",
    "        raw_df[\"tpep_dropoff_datetime\"].notna()\n",
    "    )\n",
    "    stage1 = raw_df[cond]\n",
    "    print(\"[2] 基础过滤后:\", len(stage1))\n",
    "    \n",
    "    # 时间逻辑过滤\n",
    "    time_cond = (stage1[\"tpep_dropoff_datetime\"] > stage1[\"tpep_pickup_datetime\"])\n",
    "    stage1 = stage1[time_cond]\n",
    "    print(\"[3] 时间过滤后:\", len(stage1))\n",
    "    \n",
    "    # 计算时间相关特征\n",
    "    stage1[\"trip_duration\"] = (stage1[\"tpep_dropoff_datetime\"] - stage1[\"tpep_pickup_datetime\"]).dt.total_seconds() / 3600\n",
    "    stage1[\"speed_kmh\"] = stage1[\"trip_distance\"] / stage1[\"trip_duration\"]\n",
    "    \n",
    "    # 速度过滤（放宽限制）\n",
    "    speed_cond = stage1[\"speed_kmh\"].between(0.5, 150)  # 包含低速和高速公路速度\n",
    "    stage1 = stage1[speed_cond]\n",
    "    print(\"[4] 速度过滤后:\", len(stage1))\n",
    "    \n",
    "    # 小费比例计算与过滤\n",
    "    stage1[\"tip_ratio\"] = stage1[\"tip_amount\"] / stage1[\"total_amount\"]\n",
    "    ratio_cond = stage1[\"tip_ratio\"].between(0, 1)  # 允许100%小费\n",
    "    final_df = stage1[ratio_cond]\n",
    "    print(\"[5] 最终数据量:\", len(final_df))\n",
    "    \n",
    "    # 时间特征（确保列存在）\n",
    "    final_df[\"dropoff_hour\"] = final_df[\"tpep_dropoff_datetime\"].dt.hour\n",
    "    final_df[\"dropoff_dayofweek\"] = final_df[\"tpep_dropoff_datetime\"].dt.dayofweek\n",
    "    final_df[\"is_weekend\"] = final_df[\"dropoff_dayofweek\"].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # 时段分箱（确保包含所有小时）\n",
    "    final_df[\"time_period\"] = pd.cut(\n",
    "        final_df[\"dropoff_hour\"],\n",
    "        bins=[0, 6, 9, 16, 20, 24],\n",
    "        labels=[\"Early_Morning\", \"Morning\", \"Day\", \"Evening\", \"Night\"],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# 正确调用方式：从原始数据开始处理\n",
    "positive_pay_sum_dataset = safe_preprocess(sum_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_pay_sum_dataset.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列出考虑因素和特征，以及裁剪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_count      542255\n",
      "trip_distance        542255\n",
      "speed_kmh            542255\n",
      "dropoff_hour         542255\n",
      "is_weekend           542255\n",
      "dropoff_dayofweek    542255\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 基础特征列表（不包含需要编码的类别特征）\n",
    "base_features = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"speed_kmh\",\n",
    "    \"dropoff_hour\",\n",
    "    \"is_weekend\",       # 已经是二值特征\n",
    "    \"dropoff_dayofweek\" # 作为有序类别处理\n",
    "]\n",
    "\n",
    "# 原始数据获取（包含需要编码的time_period和特征）\n",
    "processed_df = positive_pay_sum_dataset[base_features + [\"time_period\", \"tip_ratio\"]].copy()\n",
    "\n",
    "# 对类别特征进行独热编码（关键修改点）\n",
    "processed_df = pd.get_dummies(\n",
    "    processed_df, \n",
    "    columns=[\"time_period\"], \n",
    "    drop_first=True,\n",
    "    prefix=\"period\"\n",
    ")\n",
    "\n",
    "# 安全抽样（先抽样再划分数据集）\n",
    "sample_df = processed_df.sample(frac=0.01, random_state=42)\n",
    "\n",
    "# 划分数据集（必须在此步骤之后进行标准化）\n",
    "X = sample_df[base_features]\n",
    "y = sample_df[\"tip_ratio\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 定义需要标准化的连续特征（注意排除类别特征）\n",
    "continuous_features = [\n",
    "    \"passenger_count\",   # 离散但数值范围较大\n",
    "    \"trip_distance\",     # 连续\n",
    "    \"speed_kmh\",         # 连续\n",
    "    \"dropoff_hour\"       # 周期性特征\n",
    "]\n",
    "\n",
    "# 创建数据副本避免修改原始数据\n",
    "X_train_processed = X_train.copy()\n",
    "X_test_processed = X_test.copy()\n",
    "\n",
    "# 初始化标准化器（仅在训练集上fit）\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对训练集连续特征进行拟合和转换\n",
    "X_train_processed[continuous_features] = scaler.fit_transform(\n",
    "    X_train[continuous_features]\n",
    ")\n",
    "\n",
    "# 对测试集使用训练集的参数进行转换\n",
    "X_test_processed[continuous_features] = scaler.transform(\n",
    "    X_test[continuous_features]\n",
    ")\n",
    "print(X_train_processed.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型评估函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "        \"R2\": r2_score(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0634\n",
      "MSE: 0.0055\n",
      "R²: 0.0048\n"
     ]
    }
   ],
   "source": [
    "# 线性回归\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_processed, y_train)\n",
    "\n",
    "#评估模型\n",
    "lr_metrics = evaluate_model(lr_model, X_test_processed, y_test)\n",
    "print(f\"MAE: {lr_metrics['MAE']:.4f}\")\n",
    "print(f\"MSE: {lr_metrics['MSE']:.4f}\")\n",
    "print(f\"R²: {lr_metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n",
      "3.10.16 (main, Dec 11 2024, 10:22:29) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)          # 应显示 2.3.0+\n",
    "print(torch.backends.mps.is_available())  # 应返回 True\n",
    "import sys\n",
    "print(sys.version)\n",
    "# 输出示例：3.11.7 (main, Dec 15 2023, 18:24:52) [Clang 15.0.0 (clang-1500.1.0.2.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0656\n",
      "MSE: 0.0065\n",
      "R²: -0.1699\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train_processed, y_train)\n",
    "\n",
    "#评估模型\n",
    "knn_metrics = evaluate_model(knn_model, X_test_processed, y_test)\n",
    "print(f\"MAE: {knn_metrics['MAE']:.4f}\")\n",
    "print(f\"MSE: {knn_metrics['MSE']:.4f}\")\n",
    "print(f\"R²: {knn_metrics['R2']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
